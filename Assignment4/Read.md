  
Annontation done




x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 test samples
y_train shape: (50000, 1)
Learning rate:  0.0015
Model: "model_2"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 32, 32, 3)    0                                            
__________________________________________________________________________________________________
conv2d_32 (Conv2D)              (None, 32, 32, 16)   448         input_2[0][0]                    
__________________________________________________________________________________________________
batch_normalization_29 (BatchNo (None, 32, 32, 16)   64          conv2d_32[0][0]                  
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 32, 32, 16)   0           batch_normalization_29[0][0]     
__________________________________________________________________________________________________
conv2d_33 (Conv2D)              (None, 32, 32, 16)   272         activation_29[0][0]              
__________________________________________________________________________________________________
batch_normalization_30 (BatchNo (None, 32, 32, 16)   64          conv2d_33[0][0]                  
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 32, 32, 16)   0           batch_normalization_30[0][0]     
__________________________________________________________________________________________________
conv2d_34 (Conv2D)              (None, 32, 32, 16)   2320        activation_30[0][0]              
__________________________________________________________________________________________________
batch_normalization_31 (BatchNo (None, 32, 32, 16)   64          conv2d_34[0][0]                  
__________________________________________________________________________________________________
activation_31 (Activation)      (None, 32, 32, 16)   0           batch_normalization_31[0][0]     
__________________________________________________________________________________________________
conv2d_36 (Conv2D)              (None, 32, 32, 64)   1088        activation_29[0][0]              
__________________________________________________________________________________________________
conv2d_35 (Conv2D)              (None, 32, 32, 64)   1088        activation_31[0][0]              
__________________________________________________________________________________________________
add_10 (Add)                    (None, 32, 32, 64)   0           conv2d_36[0][0]                  
                                                                 conv2d_35[0][0]                  
__________________________________________________________________________________________________
batch_normalization_32 (BatchNo (None, 32, 32, 64)   256         add_10[0][0]                     
__________________________________________________________________________________________________
activation_32 (Activation)      (None, 32, 32, 64)   0           batch_normalization_32[0][0]     
__________________________________________________________________________________________________
conv2d_37 (Conv2D)              (None, 32, 32, 16)   1040        activation_32[0][0]              
__________________________________________________________________________________________________
batch_normalization_33 (BatchNo (None, 32, 32, 16)   64          conv2d_37[0][0]                  
__________________________________________________________________________________________________
activation_33 (Activation)      (None, 32, 32, 16)   0           batch_normalization_33[0][0]     
__________________________________________________________________________________________________
conv2d_38 (Conv2D)              (None, 32, 32, 16)   2320        activation_33[0][0]              
__________________________________________________________________________________________________
batch_normalization_34 (BatchNo (None, 32, 32, 16)   64          conv2d_38[0][0]                  
__________________________________________________________________________________________________
activation_34 (Activation)      (None, 32, 32, 16)   0           batch_normalization_34[0][0]     
__________________________________________________________________________________________________
conv2d_39 (Conv2D)              (None, 32, 32, 64)   1088        activation_34[0][0]              
__________________________________________________________________________________________________
add_11 (Add)                    (None, 32, 32, 64)   0           add_10[0][0]                     
                                                                 conv2d_39[0][0]                  
__________________________________________________________________________________________________
batch_normalization_35 (BatchNo (None, 32, 32, 64)   256         add_11[0][0]                     
__________________________________________________________________________________________________
activation_35 (Activation)      (None, 32, 32, 64)   0           batch_normalization_35[0][0]     
__________________________________________________________________________________________________
conv2d_40 (Conv2D)              (None, 32, 32, 16)   1040        activation_35[0][0]              
__________________________________________________________________________________________________
batch_normalization_36 (BatchNo (None, 32, 32, 16)   64          conv2d_40[0][0]                  
__________________________________________________________________________________________________
activation_36 (Activation)      (None, 32, 32, 16)   0           batch_normalization_36[0][0]     
__________________________________________________________________________________________________
conv2d_41 (Conv2D)              (None, 32, 32, 16)   2320        activation_36[0][0]              
__________________________________________________________________________________________________
batch_normalization_37 (BatchNo (None, 32, 32, 16)   64          conv2d_41[0][0]                  
__________________________________________________________________________________________________
activation_37 (Activation)      (None, 32, 32, 16)   0           batch_normalization_37[0][0]     
__________________________________________________________________________________________________
conv2d_42 (Conv2D)              (None, 32, 32, 64)   1088        activation_37[0][0]              
__________________________________________________________________________________________________
add_12 (Add)                    (None, 32, 32, 64)   0           add_11[0][0]                     
                                                                 conv2d_42[0][0]                  
__________________________________________________________________________________________________
batch_normalization_38 (BatchNo (None, 32, 32, 64)   256         add_12[0][0]                     
__________________________________________________________________________________________________
activation_38 (Activation)      (None, 32, 32, 64)   0           batch_normalization_38[0][0]     
__________________________________________________________________________________________________
conv2d_43 (Conv2D)              (None, 16, 16, 64)   4160        activation_38[0][0]              
__________________________________________________________________________________________________
batch_normalization_39 (BatchNo (None, 16, 16, 64)   256         conv2d_43[0][0]                  
__________________________________________________________________________________________________
activation_39 (Activation)      (None, 16, 16, 64)   0           batch_normalization_39[0][0]     
__________________________________________________________________________________________________
conv2d_44 (Conv2D)              (None, 16, 16, 64)   36928       activation_39[0][0]              
__________________________________________________________________________________________________
batch_normalization_40 (BatchNo (None, 16, 16, 64)   256         conv2d_44[0][0]                  
__________________________________________________________________________________________________
activation_40 (Activation)      (None, 16, 16, 64)   0           batch_normalization_40[0][0]     
__________________________________________________________________________________________________
conv2d_46 (Conv2D)              (None, 16, 16, 128)  8320        add_12[0][0]                     
__________________________________________________________________________________________________
conv2d_45 (Conv2D)              (None, 16, 16, 128)  8320        activation_40[0][0]              
__________________________________________________________________________________________________
add_13 (Add)                    (None, 16, 16, 128)  0           conv2d_46[0][0]                  
                                                                 conv2d_45[0][0]                  
__________________________________________________________________________________________________
batch_normalization_41 (BatchNo (None, 16, 16, 128)  512         add_13[0][0]                     
__________________________________________________________________________________________________
activation_41 (Activation)      (None, 16, 16, 128)  0           batch_normalization_41[0][0]     
__________________________________________________________________________________________________
conv2d_47 (Conv2D)              (None, 16, 16, 64)   8256        activation_41[0][0]              
__________________________________________________________________________________________________
batch_normalization_42 (BatchNo (None, 16, 16, 64)   256         conv2d_47[0][0]                  
__________________________________________________________________________________________________
activation_42 (Activation)      (None, 16, 16, 64)   0           batch_normalization_42[0][0]     
__________________________________________________________________________________________________
conv2d_48 (Conv2D)              (None, 16, 16, 64)   36928       activation_42[0][0]              
__________________________________________________________________________________________________
batch_normalization_43 (BatchNo (None, 16, 16, 64)   256         conv2d_48[0][0]                  
__________________________________________________________________________________________________
activation_43 (Activation)      (None, 16, 16, 64)   0           batch_normalization_43[0][0]     
__________________________________________________________________________________________________
conv2d_49 (Conv2D)              (None, 16, 16, 128)  8320        activation_43[0][0]              
__________________________________________________________________________________________________
add_14 (Add)                    (None, 16, 16, 128)  0           add_13[0][0]                     
                                                                 conv2d_49[0][0]                  
__________________________________________________________________________________________________
batch_normalization_44 (BatchNo (None, 16, 16, 128)  512         add_14[0][0]                     
__________________________________________________________________________________________________
activation_44 (Activation)      (None, 16, 16, 128)  0           batch_normalization_44[0][0]     
__________________________________________________________________________________________________
conv2d_50 (Conv2D)              (None, 16, 16, 64)   8256        activation_44[0][0]              
__________________________________________________________________________________________________
batch_normalization_45 (BatchNo (None, 16, 16, 64)   256         conv2d_50[0][0]                  
__________________________________________________________________________________________________
activation_45 (Activation)      (None, 16, 16, 64)   0           batch_normalization_45[0][0]     
__________________________________________________________________________________________________
conv2d_51 (Conv2D)              (None, 16, 16, 64)   36928       activation_45[0][0]              
__________________________________________________________________________________________________
batch_normalization_46 (BatchNo (None, 16, 16, 64)   256         conv2d_51[0][0]                  
__________________________________________________________________________________________________
activation_46 (Activation)      (None, 16, 16, 64)   0           batch_normalization_46[0][0]     
__________________________________________________________________________________________________
conv2d_52 (Conv2D)              (None, 16, 16, 128)  8320        activation_46[0][0]              
__________________________________________________________________________________________________
add_15 (Add)                    (None, 16, 16, 128)  0           add_14[0][0]                     
                                                                 conv2d_52[0][0]                  
__________________________________________________________________________________________________
batch_normalization_47 (BatchNo (None, 16, 16, 128)  512         add_15[0][0]                     
__________________________________________________________________________________________________
activation_47 (Activation)      (None, 16, 16, 128)  0           batch_normalization_47[0][0]     
__________________________________________________________________________________________________
conv2d_53 (Conv2D)              (None, 8, 8, 128)    16512       activation_47[0][0]              
__________________________________________________________________________________________________
batch_normalization_48 (BatchNo (None, 8, 8, 128)    512         conv2d_53[0][0]                  
__________________________________________________________________________________________________
activation_48 (Activation)      (None, 8, 8, 128)    0           batch_normalization_48[0][0]     
__________________________________________________________________________________________________
conv2d_54 (Conv2D)              (None, 8, 8, 128)    147584      activation_48[0][0]              
__________________________________________________________________________________________________
batch_normalization_49 (BatchNo (None, 8, 8, 128)    512         conv2d_54[0][0]                  
__________________________________________________________________________________________________
activation_49 (Activation)      (None, 8, 8, 128)    0           batch_normalization_49[0][0]     
__________________________________________________________________________________________________
conv2d_56 (Conv2D)              (None, 8, 8, 256)    33024       add_15[0][0]                     
__________________________________________________________________________________________________
conv2d_55 (Conv2D)              (None, 8, 8, 256)    33024       activation_49[0][0]              
__________________________________________________________________________________________________
add_16 (Add)                    (None, 8, 8, 256)    0           conv2d_56[0][0]                  
                                                                 conv2d_55[0][0]                  
__________________________________________________________________________________________________
batch_normalization_50 (BatchNo (None, 8, 8, 256)    1024        add_16[0][0]                     
__________________________________________________________________________________________________
activation_50 (Activation)      (None, 8, 8, 256)    0           batch_normalization_50[0][0]     
__________________________________________________________________________________________________
conv2d_57 (Conv2D)              (None, 8, 8, 128)    32896       activation_50[0][0]              
__________________________________________________________________________________________________
batch_normalization_51 (BatchNo (None, 8, 8, 128)    512         conv2d_57[0][0]                  
__________________________________________________________________________________________________
activation_51 (Activation)      (None, 8, 8, 128)    0           batch_normalization_51[0][0]     
__________________________________________________________________________________________________
conv2d_58 (Conv2D)              (None, 8, 8, 128)    147584      activation_51[0][0]              
__________________________________________________________________________________________________
batch_normalization_52 (BatchNo (None, 8, 8, 128)    512         conv2d_58[0][0]                  
__________________________________________________________________________________________________
activation_52 (Activation)      (None, 8, 8, 128)    0           batch_normalization_52[0][0]     
__________________________________________________________________________________________________
conv2d_59 (Conv2D)              (None, 8, 8, 256)    33024       activation_52[0][0]              
__________________________________________________________________________________________________
add_17 (Add)                    (None, 8, 8, 256)    0           add_16[0][0]                     
                                                                 conv2d_59[0][0]                  
__________________________________________________________________________________________________
batch_normalization_53 (BatchNo (None, 8, 8, 256)    1024        add_17[0][0]                     
__________________________________________________________________________________________________
activation_53 (Activation)      (None, 8, 8, 256)    0           batch_normalization_53[0][0]     
__________________________________________________________________________________________________
conv2d_60 (Conv2D)              (None, 8, 8, 128)    32896       activation_53[0][0]              
__________________________________________________________________________________________________
batch_normalization_54 (BatchNo (None, 8, 8, 128)    512         conv2d_60[0][0]                  
__________________________________________________________________________________________________
activation_54 (Activation)      (None, 8, 8, 128)    0           batch_normalization_54[0][0]     
__________________________________________________________________________________________________
conv2d_61 (Conv2D)              (None, 8, 8, 128)    147584      activation_54[0][0]              
__________________________________________________________________________________________________
batch_normalization_55 (BatchNo (None, 8, 8, 128)    512         conv2d_61[0][0]                  
__________________________________________________________________________________________________
activation_55 (Activation)      (None, 8, 8, 128)    0           batch_normalization_55[0][0]     
__________________________________________________________________________________________________
conv2d_62 (Conv2D)              (None, 8, 8, 256)    33024       activation_55[0][0]              
__________________________________________________________________________________________________
add_18 (Add)                    (None, 8, 8, 256)    0           add_17[0][0]                     
                                                                 conv2d_62[0][0]                  
__________________________________________________________________________________________________
batch_normalization_56 (BatchNo (None, 8, 8, 256)    1024        add_18[0][0]                     
__________________________________________________________________________________________________
activation_56 (Activation)      (None, 8, 8, 256)    0           batch_normalization_56[0][0]     
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 1, 1, 256)    0           activation_56[0][0]              
__________________________________________________________________________________________________
flatten_2 (Flatten)             (None, 256)          0           average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 10)           2570        flatten_2[0][0]                  
==================================================================================================
Total params: 849,002
Trainable params: 843,786
Non-trainable params: 5,216
__________________________________________________________________________________________________
ResNet29v2
Using real-time data augmentation.
Epoch 1/50
Learning rate:  0.0015
391/391 [==============================] - 95s 243ms/step - loss: 1.8746 - acc: 0.4930 - val_loss: 1.9509 - val_acc: 0.4808

Epoch 00001: val_acc improved from -inf to 0.48080, saving model to /content/saved_models/cifar10_ResNet29v2_model.001.h5
Epoch 2/50
Learning rate:  0.0015
391/391 [==============================] - 85s 218ms/step - loss: 1.3853 - acc: 0.6354 - val_loss: 2.1576 - val_acc: 0.5099

Epoch 00002: val_acc improved from 0.48080 to 0.50990, saving model to /content/saved_models/cifar10_ResNet29v2_model.002.h5
Epoch 3/50
Learning rate:  0.0015
391/391 [==============================] - 85s 217ms/step - loss: 1.1937 - acc: 0.6902 - val_loss: 1.2408 - val_acc: 0.6776

Epoch 00003: val_acc improved from 0.50990 to 0.67760, saving model to /content/saved_models/cifar10_ResNet29v2_model.003.h5
Epoch 4/50
Learning rate:  0.0015
391/391 [==============================] - 85s 218ms/step - loss: 1.0769 - acc: 0.7276 - val_loss: 1.2543 - val_acc: 0.6613

Epoch 00004: val_acc did not improve from 0.67760
Epoch 5/50
Learning rate:  0.0015
391/391 [==============================] - 85s 218ms/step - loss: 0.9971 - acc: 0.7538 - val_loss: 1.0915 - val_acc: 0.7226

Epoch 00005: val_acc improved from 0.67760 to 0.72260, saving model to /content/saved_models/cifar10_ResNet29v2_model.005.h5
Epoch 6/50
Learning rate:  0.0015
391/391 [==============================] - 85s 218ms/step - loss: 0.9361 - acc: 0.7697 - val_loss: 1.2014 - val_acc: 0.6890

Epoch 00006: val_acc did not improve from 0.72260
Epoch 7/50
Learning rate:  0.0015
391/391 [==============================] - 85s 218ms/step - loss: 0.8874 - acc: 0.7857 - val_loss: 1.0782 - val_acc: 0.7188

Epoch 00007: val_acc did not improve from 0.72260
Epoch 8/50
Learning rate:  0.0015
391/391 [==============================] - 85s 218ms/step - loss: 0.8513 - acc: 0.7966 - val_loss: 1.1813 - val_acc: 0.7247

Epoch 00008: val_acc improved from 0.72260 to 0.72470, saving model to /content/saved_models/cifar10_ResNet29v2_model.008.h5
Epoch 9/50
Learning rate:  0.0015
391/391 [==============================] - 85s 218ms/step - loss: 0.8159 - acc: 0.8043 - val_loss: 1.0476 - val_acc: 0.7394

Epoch 00009: val_acc improved from 0.72470 to 0.73940, saving model to /content/saved_models/cifar10_ResNet29v2_model.009.h5
Epoch 10/50
Learning rate:  0.0015
391/391 [==============================] - 85s 217ms/step - loss: 0.7920 - acc: 0.8154 - val_loss: 0.9323 - val_acc: 0.7748

Epoch 00010: val_acc improved from 0.73940 to 0.77480, saving model to /content/saved_models/cifar10_ResNet29v2_model.010.h5
Epoch 11/50
Learning rate:  0.0015
391/391 [==============================] - 85s 218ms/step - loss: 0.7688 - acc: 0.8215 - val_loss: 1.0169 - val_acc: 0.7359

Epoch 00011: val_acc did not improve from 0.77480
Epoch 12/50
Learning rate:  0.001
391/391 [==============================] - 85s 218ms/step - loss: 0.6869 - acc: 0.8472 - val_loss: 0.9406 - val_acc: 0.7701

Epoch 00012: val_acc did not improve from 0.77480
Epoch 13/50
Learning rate:  0.001
391/391 [==============================] - 85s 218ms/step - loss: 0.6628 - acc: 0.8514 - val_loss: 0.9340 - val_acc: 0.7799

Epoch 00013: val_acc improved from 0.77480 to 0.77990, saving model to /content/saved_models/cifar10_ResNet29v2_model.013.h5
Epoch 14/50
Learning rate:  0.001
391/391 [==============================] - 85s 218ms/step - loss: 0.6443 - acc: 0.8557 - val_loss: 0.8311 - val_acc: 0.7977

Epoch 00014: val_acc improved from 0.77990 to 0.79770, saving model to /content/saved_models/cifar10_ResNet29v2_model.014.h5
Epoch 15/50
Learning rate:  0.001
391/391 [==============================] - 85s 218ms/step - loss: 0.6231 - acc: 0.8629 - val_loss: 0.9863 - val_acc: 0.7438

Epoch 00015: val_acc did not improve from 0.79770
Epoch 16/50
Learning rate:  0.001
391/391 [==============================] - 85s 217ms/step - loss: 0.6080 - acc: 0.8661 - val_loss: 0.8415 - val_acc: 0.7950

Epoch 00016: val_acc did not improve from 0.79770
Epoch 17/50
Learning rate:  0.001
391/391 [==============================] - 85s 217ms/step - loss: 0.5996 - acc: 0.8697 - val_loss: 1.0318 - val_acc: 0.7571

Epoch 00017: val_acc did not improve from 0.79770
Epoch 18/50
Learning rate:  0.001
391/391 [==============================] - 84s 216ms/step - loss: 0.5861 - acc: 0.8716 - val_loss: 0.7766 - val_acc: 0.8186

Epoch 00018: val_acc improved from 0.79770 to 0.81860, saving model to /content/saved_models/cifar10_ResNet29v2_model.018.h5
Epoch 19/50
Learning rate:  0.001
391/391 [==============================] - 85s 217ms/step - loss: 0.5752 - acc: 0.8752 - val_loss: 0.8207 - val_acc: 0.8050

Epoch 00019: val_acc did not improve from 0.81860
Epoch 20/50
Learning rate:  0.001
391/391 [==============================] - 84s 215ms/step - loss: 0.5615 - acc: 0.8798 - val_loss: 0.8611 - val_acc: 0.8047

Epoch 00020: val_acc did not improve from 0.81860
Epoch 21/50
Learning rate:  0.001
391/391 [==============================] - 84s 214ms/step - loss: 0.5537 - acc: 0.8819 - val_loss: 0.7675 - val_acc: 0.8237

Epoch 00021: val_acc improved from 0.81860 to 0.82370, saving model to /content/saved_models/cifar10_ResNet29v2_model.021.h5
Epoch 22/50
Learning rate:  0.0005
391/391 [==============================] - 85s 217ms/step - loss: 0.4803 - acc: 0.9063 - val_loss: 0.6103 - val_acc: 0.8679

Epoch 00022: val_acc improved from 0.82370 to 0.86790, saving model to /content/saved_models/cifar10_ResNet29v2_model.022.h5
Epoch 23/50
Learning rate:  0.0005
391/391 [==============================] - 85s 218ms/step - loss: 0.4594 - acc: 0.9112 - val_loss: 0.6311 - val_acc: 0.8541

Epoch 00023: val_acc did not improve from 0.86790
Epoch 24/50
Learning rate:  0.0005
391/391 [==============================] - 85s 217ms/step - loss: 0.4528 - acc: 0.9113 - val_loss: 0.7384 - val_acc: 0.8293

Epoch 00024: val_acc did not improve from 0.86790
Epoch 25/50
Learning rate:  0.0005
391/391 [==============================] - 85s 218ms/step - loss: 0.4343 - acc: 0.9161 - val_loss: 0.6212 - val_acc: 0.8659

Epoch 00025: val_acc did not improve from 0.86790
Epoch 26/50
Learning rate:  0.0005
391/391 [==============================] - 85s 218ms/step - loss: 0.4260 - acc: 0.9182 - val_loss: 0.6070 - val_acc: 0.8624

Epoch 00026: val_acc did not improve from 0.86790
Epoch 27/50
Learning rate:  0.0005
391/391 [==============================] - 85s 218ms/step - loss: 0.4170 - acc: 0.9199 - val_loss: 0.8505 - val_acc: 0.8074

Epoch 00027: val_acc did not improve from 0.86790
Epoch 28/50
Learning rate:  0.0005
391/391 [==============================] - 85s 218ms/step - loss: 0.4041 - acc: 0.9238 - val_loss: 0.6646 - val_acc: 0.8512

Epoch 00028: val_acc did not improve from 0.86790
Epoch 29/50
Learning rate:  0.0005
391/391 [==============================] - 85s 217ms/step - loss: 0.4019 - acc: 0.9239 - val_loss: 0.6110 - val_acc: 0.8678

Epoch 00029: val_acc did not improve from 0.86790
Epoch 30/50
Learning rate:  0.0005
391/391 [==============================] - 85s 217ms/step - loss: 0.3935 - acc: 0.9265 - val_loss: 0.6883 - val_acc: 0.8452

Epoch 00030: val_acc did not improve from 0.86790
Epoch 31/50
Learning rate:  0.0005
391/391 [==============================] - 85s 217ms/step - loss: 0.3863 - acc: 0.9269 - val_loss: 0.6634 - val_acc: 0.8491

Epoch 00031: val_acc did not improve from 0.86790
Epoch 32/50
Learning rate:  0.0005
391/391 [==============================] - 85s 216ms/step - loss: 0.3849 - acc: 0.9281 - val_loss: 0.6341 - val_acc: 0.8564

Epoch 00032: val_acc did not improve from 0.86790
Epoch 33/50
Learning rate:  0.0005
391/391 [==============================] - 85s 217ms/step - loss: 0.3788 - acc: 0.9283 - val_loss: 0.8923 - val_acc: 0.8035

Epoch 00033: val_acc did not improve from 0.86790
Epoch 34/50
Learning rate:  0.0005
391/391 [==============================] - 84s 216ms/step - loss: 0.3717 - acc: 0.9317 - val_loss: 0.7018 - val_acc: 0.8496

Epoch 00034: val_acc did not improve from 0.86790
Epoch 35/50
Learning rate:  0.0005
391/391 [==============================] - 84s 215ms/step - loss: 0.3702 - acc: 0.9311 - val_loss: 0.6119 - val_acc: 0.8647

Epoch 00035: val_acc did not improve from 0.86790
Epoch 36/50
Learning rate:  0.0005
391/391 [==============================] - 84s 215ms/step - loss: 0.3595 - acc: 0.9346 - val_loss: 0.8051 - val_acc: 0.8288

Epoch 00036: val_acc did not improve from 0.86790
Epoch 37/50
Learning rate:  0.0001
391/391 [==============================] - 85s 217ms/step - loss: 0.3075 - acc: 0.9540 - val_loss: 0.4915 - val_acc: 0.9018

Epoch 00037: val_acc improved from 0.86790 to 0.90180, saving model to /content/saved_models/cifar10_ResNet29v2_model.037.h5
Epoch 38/50
Learning rate:  0.0001
391/391 [==============================] - 85s 217ms/step - loss: 0.2911 - acc: 0.9600 - val_loss: 0.4965 - val_acc: 0.8991

Epoch 00038: val_acc did not improve from 0.90180
Epoch 39/50
Learning rate:  0.0001
391/391 [==============================] - 85s 217ms/step - loss: 0.2818 - acc: 0.9631 - val_loss: 0.5094 - val_acc: 0.9002

Epoch 00039: val_acc did not improve from 0.90180
Epoch 40/50
Learning rate:  0.0001
391/391 [==============================] - 84s 216ms/step - loss: 0.2772 - acc: 0.9636 - val_loss: 0.5001 - val_acc: 0.9001

Epoch 00040: val_acc did not improve from 0.90180
Epoch 41/50
Learning rate:  0.0001
391/391 [==============================] - 85s 217ms/step - loss: 0.2683 - acc: 0.9668 - val_loss: 0.5071 - val_acc: 0.9002

Epoch 00041: val_acc did not improve from 0.90180
Epoch 42/50
Learning rate:  0.0001
391/391 [==============================] - 85s 217ms/step - loss: 0.2665 - acc: 0.9657 - val_loss: 0.4981 - val_acc: 0.9008

Epoch 00042: val_acc did not improve from 0.90180
Epoch 43/50
Learning rate:  0.0001
391/391 [==============================] - 84s 215ms/step - loss: 0.2595 - acc: 0.9682 - val_loss: 0.5203 - val_acc: 0.8991

Epoch 00043: val_acc did not improve from 0.90180
Epoch 44/50
Learning rate:  0.0001
391/391 [==============================] - 84s 214ms/step - loss: 0.2567 - acc: 0.9692 - val_loss: 0.5048 - val_acc: 0.9024

Epoch 00044: val_acc improved from 0.90180 to 0.90240, saving model to /content/saved_models/cifar10_ResNet29v2_model.044.h5
Epoch 45/50
Learning rate:  0.0001
391/391 [==============================] - 84s 214ms/step - loss: 0.2510 - acc: 0.9711 - val_loss: 0.5089 - val_acc: 0.8980

Epoch 00045: val_acc did not improve from 0.90240
Epoch 46/50
Learning rate:  0.0001
391/391 [==============================] - 84s 215ms/step - loss: 0.2473 - acc: 0.9713 - val_loss: 0.5098 - val_acc: 0.8997

Epoch 00046: val_acc did not improve from 0.90240
Epoch 47/50
Learning rate:  0.0001
391/391 [==============================] - 84s 214ms/step - loss: 0.2435 - acc: 0.9724 - val_loss: 0.5352 - val_acc: 0.8938

Epoch 00047: val_acc did not improve from 0.90240
Epoch 48/50
Learning rate:  0.0001
391/391 [==============================] - 84s 214ms/step - loss: 0.2433 - acc: 0.9719 - val_loss: 0.5003 - val_acc: 0.9030

Epoch 00048: val_acc improved from 0.90240 to 0.90300, saving model to /content/saved_models/cifar10_ResNet29v2_model.048.h5
Epoch 49/50
Learning rate:  0.0001
391/391 [==============================] - 84s 215ms/step - loss: 0.2389 - acc: 0.9734 - val_loss: 0.5120 - val_acc: 0.9034

Epoch 00049: val_acc improved from 0.90300 to 0.90340, saving model to /content/saved_models/cifar10_ResNet29v2_model.049.h5
Epoch 50/50
Learning rate:  0.0001
391/391 [==============================] - 84s 215ms/step - loss: 0.2353 - acc: 0.9748 - val_loss: 0.5039 - val_acc: 0.9062

Epoch 00050: val_acc improved from 0.90340 to 0.90620, saving model to /content/saved_models/cifar10_ResNet29v2_model.050.h5
10000/10000 [==============================] - 7s 690us/step
Test loss: 0.5038535665512085
Test accuracy: 0.9062
